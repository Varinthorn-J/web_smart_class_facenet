{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2 # opencv\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras import backend\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = np.asarray(image)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    #for i in range(len(results)):\n",
    "    # extract the bounding box from the first face\n",
    "    for i in range(len(results)):\n",
    "        x1, y1, width, height = results[i]['box']\n",
    "        # deal with negative pixel index\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = np.asarray(image)\n",
    "        return face_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_face(dir):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in os.listdir(dir):\n",
    "        path = dir + filename\n",
    "        face = extract_face(path)\n",
    "        faces.append(face)\n",
    "    return faces\n",
    "\n",
    "def load_dataset(dir):\n",
    "    # list for faces and labels\n",
    "    X, y = list(), list()\n",
    "    for subdir in os.listdir(dir):\n",
    "        path = dir + subdir + '/'\n",
    "        faces = load_face(path)\n",
    "        labels = [subdir for i in range(len(faces))]\n",
    "        print(\"loaded %d sample for class: %s\" % (len(faces),subdir) ) # print progress\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    โหลด dataset จากไฟล์ datas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 55 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000263135763A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026312E1F1F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "loaded 5 sample for class: Alameen\n",
      "loaded 16 sample for class: Apinun\n",
      "loaded 17 sample for class: Arim\n",
      "loaded 17 sample for class: Chanchanok\n",
      "loaded 9 sample for class: Chareef\n",
      "loaded 14 sample for class: Jantapa\n",
      "loaded 8 sample for class: Jetnipat\n",
      "loaded 17 sample for class: Kanda\n",
      "loaded 18 sample for class: Ketsiree\n",
      "loaded 15 sample for class: Nanfa\n",
      "loaded 14 sample for class: Napadsakorn\n",
      "loaded 7 sample for class: Naslimin\n",
      "loaded 13 sample for class: Natthapon\n",
      "loaded 10 sample for class: Natthawut\n",
      "loaded 12 sample for class: Nattida\n",
      "loaded 16 sample for class: Nichakan\n",
      "loaded 15 sample for class: Pajaree\n",
      "loaded 12 sample for class: Panjira\n",
      "loaded 10 sample for class: Pattanun\n",
      "loaded 18 sample for class: Phimwadi\n",
      "loaded 10 sample for class: Phiraphon\n",
      "loaded 15 sample for class: Ruchikon\n",
      "loaded 15 sample for class: Santi\n",
      "loaded 21 sample for class: Santiphap\n",
      "loaded 12 sample for class: Sarawadee\n",
      "loaded 14 sample for class: Sarayut\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy = load_dataset('./datas/train/')\n",
    "print(trainX.shape, trainy.shape)\n",
    "# load test dataset\n",
    "testX, testy = load_dataset('./datas/val/')\n",
    "print(testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    บีบอัดข้อมูล dataset จะได้ file npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('faces-dataset.npz', trainX, trainy, testX, testy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet_model = load_model('./facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('faces-dataset.npz',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทำ embedding ใบหน้า "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face):\n",
    "    # scale pixel values\n",
    "    face = face.astype('float32')\n",
    "    # standardization\n",
    "    mean, std = face.mean(), face.std()\n",
    "    face = (face-mean)/std\n",
    "    # transfer face into one sample (3 dimension to 4 dimension)\n",
    "    sample = np.expand_dims(face, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(sample)\n",
    "    return yhat[0]\n",
    "\n",
    "emdTrainX = list()\n",
    "for face in trainX:\n",
    "    emd = get_embedding(facenet_model, face)    \n",
    "    emdTrainX.append(emd)    \n",
    "emdTrainX = np.asarray(emdTrainX)\n",
    "print(emdTrainX.shape)\n",
    "\n",
    "\n",
    "emdTestX = list()\n",
    "for face in testX:\n",
    "    emd = get_embedding(facenet_model, face)\n",
    "    emdTestX.append(emd)\n",
    "emdTestX = np.asarray(emdTestX)\n",
    "print(emdTestX.shape)\n",
    "np.savez_compressed('faces-embeddings.npz', emdTrainX, trainy, emdTestX, testy) \n",
    "print(\"save face-embeddings success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tarin and predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_encoder = Normalizer()\n",
    "emdTrainX_norm = in_encoder.transform(emdTrainX)\n",
    "emdTestX_norm = in_encoder.transform(emdTestX)\n",
    "\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy_enc = out_encoder.transform(trainy)\n",
    "testy_enc = out_encoder.transform(testy)\n",
    "\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "pred= model.fit(emdTrainX_norm, trainy_enc)\n",
    "\n",
    "yhat_train = model.predict(emdTrainX_norm)\n",
    "yhat_test = model.predict(emdTestX_norm)\n",
    "\n",
    "score_train = accuracy_score(trainy_enc, yhat_train)\n",
    "score_test = accuracy_score(testy_enc, yhat_test)\n",
    "\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yhat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(testy_enc, yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('./data/train/Warinthon/Warinthon2.jpg')\n",
    "image = image.convert('RGB')\n",
    "pixels = np.asarray(image)\n",
    "detector = MTCNN()\n",
    "results = detector.detect_faces(pixels)\n",
    "for i in range(len(results)):\n",
    "    x1, y1, width, height = results[i]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize((160,160))\n",
    "    face_array = np.asarray(image)\n",
    "    cv2.imwrite('./data/img_{}.jpg'.format(i),face_array)\n",
    "    \n",
    "    \n",
    "data = list()\n",
    "for i in glob.glob('data/*.jpg', recursive=True):\n",
    "    data.append(cv2.imread(i))\n",
    "emdTestX = list()\n",
    "for face in data:\n",
    "    emd = get_embedding(facenet_model, face)\n",
    "    emdTestX.append(emd)\n",
    "emdTestX = np.asarray(emdTestX)\n",
    "emdTestX_norm = in_encoder.transform(emdTestX)\n",
    "yhat_test = model.predict(emdTestX_norm)\n",
    "print(yhat_test)\n",
    "predict_name = out_encoder.inverse_transform(yhat_test)\n",
    "print(predict_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yhat_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot\n",
    "\n",
    "yhat_prob = model.predict_proba(emdTestX_norm)\n",
    "class_index = yhat_test[0]\n",
    "class_probability = yhat_prob[0,class_index] * 100\n",
    "predict_names = out_encoder.inverse_transform(yhat_test)\n",
    "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yhat_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('score.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(yhat_test)):\n",
    "    print(yhat_test[i])\n",
    "    predict_name = out_encoder.inverse_transform(yhat_test)\n",
    "    #df.at[i,'name'] = predict_name[i]\n",
    "    df.at[yhat_test[i],'score'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('pandas_simple.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d4d61b936b60b5bc6ff9fb0e62222b0cfefae76eccb24eb6ffe2e80675ee1b9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
