{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2 # opencv\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras import backend\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = np.asarray(image)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    #for i in range(len(results)):\n",
    "    # extract the bounding box from the first face\n",
    "    for i in range(len(results)):\n",
    "        x1, y1, width, height = results[i]['box']\n",
    "        # deal with negative pixel index\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = np.asarray(image)\n",
    "        return face_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_face(dir):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in os.listdir(dir):\n",
    "        path = dir + filename\n",
    "        face = extract_face(path)\n",
    "        faces.append(face)\n",
    "    return faces\n",
    "\n",
    "def load_dataset(dir):\n",
    "    # list for faces and labels\n",
    "    X, y = list(), list()\n",
    "    for subdir in os.listdir(dir):\n",
    "        path = dir + subdir + '/'\n",
    "        faces = load_face(path)\n",
    "        labels = [subdir for i in range(len(faces))]\n",
    "        print(\"loaded %d sample for class: %s\" % (len(faces),subdir) ) # print progress\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    โหลด dataset จากไฟล์ datas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 55 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000114AA8AC3A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 55 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000114AAAFD708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "loaded 25 sample for class: Alameen\n",
      "loaded 40 sample for class: Apinun\n",
      "loaded 40 sample for class: Arim\n",
      "loaded 40 sample for class: Chanchanok\n",
      "loaded 40 sample for class: Chareef\n",
      "loaded 40 sample for class: Jantapa\n",
      "loaded 40 sample for class: Jetnipat\n",
      "loaded 40 sample for class: Kanda\n",
      "loaded 40 sample for class: Ketsiree\n",
      "loaded 40 sample for class: Nanfa\n",
      "loaded 40 sample for class: Napadsakorn\n",
      "loaded 40 sample for class: Naslimin\n",
      "loaded 40 sample for class: Natthapon\n",
      "loaded 40 sample for class: Natthawut\n",
      "loaded 40 sample for class: Nattida\n",
      "loaded 40 sample for class: Nichakan\n",
      "loaded 40 sample for class: Pajaree\n",
      "loaded 40 sample for class: Panjira\n",
      "loaded 40 sample for class: Pattanun\n",
      "loaded 40 sample for class: Phimwadi\n",
      "loaded 40 sample for class: Phiraphon\n",
      "loaded 40 sample for class: Ruchikon\n",
      "loaded 40 sample for class: Santi\n",
      "loaded 40 sample for class: Santiphap\n",
      "loaded 40 sample for class: Sarawadee\n",
      "loaded 40 sample for class: Sarayut\n",
      "loaded 40 sample for class: Sorawit\n",
      "loaded 40 sample for class: Sufian\n",
      "loaded 40 sample for class: Sutthisarn\n",
      "loaded 40 sample for class: Tannut\n",
      "loaded 40 sample for class: Teeraphat\n",
      "loaded 40 sample for class: Teerayut\n",
      "loaded 28 sample for class: Thodsapon\n",
      "loaded 40 sample for class: Waraporn\n",
      "loaded 40 sample for class: Warinthon\n",
      "(1373, 160, 160, 3) (1373,)\n",
      "loaded 5 sample for class: Alameen\n",
      "loaded 8 sample for class: Apinun\n",
      "loaded 10 sample for class: Arim\n",
      "loaded 10 sample for class: Chanchanok\n",
      "loaded 9 sample for class: Chareef\n",
      "loaded 10 sample for class: Jantapa\n",
      "loaded 8 sample for class: Jetnipat\n",
      "loaded 10 sample for class: Kanda\n",
      "loaded 10 sample for class: Ketsiree\n",
      "loaded 10 sample for class: Nanfa\n",
      "loaded 9 sample for class: Napadsakorn\n",
      "loaded 7 sample for class: Naslimin\n",
      "loaded 10 sample for class: Natthapon\n",
      "loaded 10 sample for class: Natthawut\n",
      "loaded 10 sample for class: Nattida\n",
      "loaded 10 sample for class: Nichakan\n",
      "loaded 10 sample for class: Pajaree\n",
      "loaded 10 sample for class: Panjira\n",
      "loaded 8 sample for class: Pattanun\n",
      "loaded 10 sample for class: Phimwadi\n",
      "loaded 9 sample for class: Phiraphon\n",
      "loaded 7 sample for class: Ruchikon\n",
      "loaded 10 sample for class: Santi\n",
      "loaded 10 sample for class: Santiphap\n",
      "loaded 10 sample for class: Sarawadee\n",
      "loaded 10 sample for class: Sarayut\n",
      "loaded 9 sample for class: Sorawit\n",
      "loaded 9 sample for class: Sufian\n",
      "loaded 10 sample for class: Sutthisarn\n",
      "loaded 9 sample for class: Tannut\n",
      "loaded 6 sample for class: Teeraphat\n",
      "loaded 10 sample for class: Teerayut\n",
      "loaded 5 sample for class: Thodsapon\n",
      "loaded 10 sample for class: Waraporn\n",
      "loaded 9 sample for class: Warinthon\n",
      "(317, 160, 160, 3) (317,)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy = load_dataset('./datas/train/')\n",
    "print(trainX.shape, trainy.shape)\n",
    "# load test dataset\n",
    "testX, testy = load_dataset('./datas/val/')\n",
    "print(testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    บีบอัดข้อมูล dataset จะได้ file npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('faces-dataset.npz', trainX, trainy, testX, testy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "facenet_model = load_model('./facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('faces-dataset.npz',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  (1373, 160, 160, 3) (1373,) (317, 160, 160, 3) (317,)\n"
     ]
    }
   ],
   "source": [
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทำ embedding ใบหน้า "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1373, 128)\n",
      "(317, 128)\n",
      "save face-embeddings success\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(model, face):\n",
    "    # scale pixel values\n",
    "    face = face.astype('float32')\n",
    "    # standardization\n",
    "    mean, std = face.mean(), face.std()\n",
    "    face = (face-mean)/std\n",
    "    # transfer face into one sample (3 dimension to 4 dimension)\n",
    "    sample = np.expand_dims(face, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(sample)\n",
    "    return yhat[0]\n",
    "\n",
    "emdTrainX = list()\n",
    "for face in trainX:\n",
    "    emd = get_embedding(facenet_model, face)    \n",
    "    emdTrainX.append(emd)    \n",
    "emdTrainX = np.asarray(emdTrainX)\n",
    "print(emdTrainX.shape)\n",
    "\n",
    "\n",
    "emdTestX = list()\n",
    "for face in testX:\n",
    "    emd = get_embedding(facenet_model, face)\n",
    "    emdTestX.append(emd)\n",
    "emdTestX = np.asarray(emdTestX)\n",
    "print(emdTestX.shape)\n",
    "np.savez_compressed('faces-embeddings.npz', emdTrainX, trainy, emdTestX, testy) \n",
    "print(\"save face-embeddings success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tarin and predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: train=100.000, test=100.000\n"
     ]
    }
   ],
   "source": [
    "in_encoder = Normalizer()\n",
    "emdTrainX_norm = in_encoder.transform(emdTrainX)\n",
    "emdTestX_norm = in_encoder.transform(emdTestX)\n",
    "\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy_enc = out_encoder.transform(trainy)\n",
    "testy_enc = out_encoder.transform(testy)\n",
    "\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "pred= model.fit(emdTrainX_norm, trainy_enc)\n",
    "\n",
    "yhat_train = model.predict(emdTrainX_norm)\n",
    "yhat_test = model.predict(emdTestX_norm)\n",
    "\n",
    "score_train = accuracy_score(trainy_enc, yhat_train)\n",
    "score_test = accuracy_score(testy_enc, yhat_test)\n",
    "\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  3\n",
      "  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5\n",
      "  5  5  5  5  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  8  8\n",
      "  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10\n",
      " 10 10 10 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 13 13 13 13\n",
      " 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15\n",
      " 15 15 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 18 18\n",
      " 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20\n",
      " 20 21 21 21 21 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23\n",
      " 23 23 23 23 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25\n",
      " 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 28 28 28 28 28 28\n",
      " 28 28 28 28 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 31 31 31 31 31\n",
      " 31 31 31 31 31 32 32 32 32 32 33 33 33 33 33 33 33 33 33 33 34 34 34 34\n",
      " 34 34 34 34 34]\n"
     ]
    }
   ],
   "source": [
    "print(yhat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  8,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0, 10, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  5,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0, 10,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(testy_enc, yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n",
      "['Chareef']\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./datas/val/Chareef/3.jpg')\n",
    "image = image.convert('RGB')\n",
    "pixels = np.asarray(image)\n",
    "detector = MTCNN()\n",
    "results = detector.detect_faces(pixels)\n",
    "for i in range(len(results)):\n",
    "    x1, y1, width, height = results[i]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize((160,160))\n",
    "    face_array = np.asarray(image)\n",
    "    cv2.imwrite('./data/img_{}.jpg'.format(i),face_array)\n",
    "    \n",
    "    \n",
    "data = list()\n",
    "for i in glob.glob('data/*.jpg', recursive=True):\n",
    "    data.append(cv2.imread(i))\n",
    "emdTestX = list()\n",
    "for face in data:\n",
    "    emd = get_embedding(facenet_model, face)\n",
    "    emdTestX.append(emd)\n",
    "emdTestX = np.asarray(emdTestX)\n",
    "emdTestX_norm = in_encoder.transform(emdTestX)\n",
    "yhat_test = model.predict(emdTestX_norm)\n",
    "print(yhat_test)\n",
    "predict_name = out_encoder.inverse_transform(yhat_test)\n",
    "print(predict_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(yhat_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Chareef (61.551)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot\n",
    "\n",
    "yhat_prob = model.predict_proba(emdTestX_norm)\n",
    "class_index = yhat_test[0]\n",
    "class_probability = yhat_prob[0,class_index] * 100\n",
    "predict_names = out_encoder.inverse_transform(yhat_test)\n",
    "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(yhat_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6035512001</td>\n",
       "      <td>Alameen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6035512002</td>\n",
       "      <td>Apinun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6035512003</td>\n",
       "      <td>Arim</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6035512004</td>\n",
       "      <td>Chanchanok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6035512005</td>\n",
       "      <td>Chareef</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6035512006</td>\n",
       "      <td>Jantapa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6035512007</td>\n",
       "      <td>Jetnipat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6035512008</td>\n",
       "      <td>Kanda</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>6035512009</td>\n",
       "      <td>Ketsiree</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>6035512010</td>\n",
       "      <td>Nanfa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>6035512011</td>\n",
       "      <td>Napadsakorn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>6035512012</td>\n",
       "      <td>Naslimin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>6035512013</td>\n",
       "      <td>Natthapon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>6035512014</td>\n",
       "      <td>Natthawut</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>6035512015</td>\n",
       "      <td>Nattida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>6035512016</td>\n",
       "      <td>Nichakan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>6035512017</td>\n",
       "      <td>Pajaree</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>6035512018</td>\n",
       "      <td>Panjira</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>6135512002</td>\n",
       "      <td>Pattanun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>6035512019</td>\n",
       "      <td>Phimwadi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>6035512020</td>\n",
       "      <td>Phiraphon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>6135512005</td>\n",
       "      <td>Ruchikon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>6035512021</td>\n",
       "      <td>Santi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>6035512022</td>\n",
       "      <td>Santiphap</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>6035512023</td>\n",
       "      <td>Sarawadee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>6035512024</td>\n",
       "      <td>Sarayut</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>6035512025</td>\n",
       "      <td>Sorawit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>6135512028</td>\n",
       "      <td>Sufian</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>6035512026</td>\n",
       "      <td>Sutthisarn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>6135512016</td>\n",
       "      <td>Tannut</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>6035512027</td>\n",
       "      <td>Teeraphat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>6035512028</td>\n",
       "      <td>Teerayut</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>6035512029</td>\n",
       "      <td>Thodsapon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>6035512030</td>\n",
       "      <td>Waraporn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>6135512053</td>\n",
       "      <td>Warinthon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    no          id         name  score\n",
       "0    1  6035512001      Alameen    NaN\n",
       "1    2  6035512002       Apinun    NaN\n",
       "2    3  6035512003         Arim    NaN\n",
       "3    4  6035512004   Chanchanok    NaN\n",
       "4    5  6035512005      Chareef    NaN\n",
       "5    6  6035512006      Jantapa    NaN\n",
       "6    7  6035512007     Jetnipat    NaN\n",
       "7    8  6035512008        Kanda    NaN\n",
       "8    9  6035512009     Ketsiree    NaN\n",
       "9   10  6035512010        Nanfa    NaN\n",
       "10  11  6035512011  Napadsakorn    NaN\n",
       "11  12  6035512012     Naslimin    NaN\n",
       "12  13  6035512013    Natthapon    NaN\n",
       "13  14  6035512014    Natthawut    NaN\n",
       "14  15  6035512015      Nattida    NaN\n",
       "15  16  6035512016     Nichakan    NaN\n",
       "16  17  6035512017      Pajaree    NaN\n",
       "17  18  6035512018      Panjira    NaN\n",
       "18  19  6135512002     Pattanun    NaN\n",
       "19  20  6035512019     Phimwadi    NaN\n",
       "20  21  6035512020    Phiraphon    NaN\n",
       "21  22  6135512005     Ruchikon    NaN\n",
       "22  23  6035512021        Santi    NaN\n",
       "23  24  6035512022    Santiphap    NaN\n",
       "24  25  6035512023    Sarawadee    NaN\n",
       "25  26  6035512024      Sarayut    NaN\n",
       "26  27  6035512025      Sorawit    NaN\n",
       "27  28  6135512028       Sufian    NaN\n",
       "28  29  6035512026   Sutthisarn    NaN\n",
       "29  30  6135512016       Tannut    NaN\n",
       "30  31  6035512027    Teeraphat    NaN\n",
       "31  32  6035512028     Teerayut    NaN\n",
       "32  33  6035512029    Thodsapon    NaN\n",
       "33  34  6035512030     Waraporn    NaN\n",
       "34  35  6135512053    Warinthon    NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('score.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(yhat_test)):\n",
    "    print(yhat_test[i])\n",
    "    predict_name = out_encoder.inverse_transform(yhat_test)\n",
    "    #df.at[i,'name'] = predict_name[i]\n",
    "    df.at[yhat_test[i],'score'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6035512001</td>\n",
       "      <td>Alameen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6035512002</td>\n",
       "      <td>Apinun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6035512003</td>\n",
       "      <td>Arim</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6035512004</td>\n",
       "      <td>Chanchanok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6035512005</td>\n",
       "      <td>Chareef</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6035512006</td>\n",
       "      <td>Jantapa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6035512007</td>\n",
       "      <td>Jetnipat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6035512008</td>\n",
       "      <td>Kanda</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>6035512009</td>\n",
       "      <td>Ketsiree</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>6035512010</td>\n",
       "      <td>Nanfa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>6035512011</td>\n",
       "      <td>Napadsakorn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>6035512012</td>\n",
       "      <td>Naslimin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>6035512013</td>\n",
       "      <td>Natthapon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>6035512014</td>\n",
       "      <td>Natthawut</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>6035512015</td>\n",
       "      <td>Nattida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>6035512016</td>\n",
       "      <td>Nichakan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>6035512017</td>\n",
       "      <td>Pajaree</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>6035512018</td>\n",
       "      <td>Panjira</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>6135512002</td>\n",
       "      <td>Pattanun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>6035512019</td>\n",
       "      <td>Phimwadi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>6035512020</td>\n",
       "      <td>Phiraphon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>6135512005</td>\n",
       "      <td>Ruchikon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>6035512021</td>\n",
       "      <td>Santi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>6035512022</td>\n",
       "      <td>Santiphap</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>6035512023</td>\n",
       "      <td>Sarawadee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>6035512024</td>\n",
       "      <td>Sarayut</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>6035512025</td>\n",
       "      <td>Sorawit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>6135512028</td>\n",
       "      <td>Sufian</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>6035512026</td>\n",
       "      <td>Sutthisarn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>6135512016</td>\n",
       "      <td>Tannut</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>6035512027</td>\n",
       "      <td>Teeraphat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>6035512028</td>\n",
       "      <td>Teerayut</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>6035512029</td>\n",
       "      <td>Thodsapon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>6035512030</td>\n",
       "      <td>Waraporn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>6135512053</td>\n",
       "      <td>Warinthon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    no          id         name  score\n",
       "0    1  6035512001      Alameen    NaN\n",
       "1    2  6035512002       Apinun    NaN\n",
       "2    3  6035512003         Arim    NaN\n",
       "3    4  6035512004   Chanchanok    NaN\n",
       "4    5  6035512005      Chareef    1.0\n",
       "5    6  6035512006      Jantapa    NaN\n",
       "6    7  6035512007     Jetnipat    NaN\n",
       "7    8  6035512008        Kanda    NaN\n",
       "8    9  6035512009     Ketsiree    NaN\n",
       "9   10  6035512010        Nanfa    NaN\n",
       "10  11  6035512011  Napadsakorn    NaN\n",
       "11  12  6035512012     Naslimin    NaN\n",
       "12  13  6035512013    Natthapon    NaN\n",
       "13  14  6035512014    Natthawut    NaN\n",
       "14  15  6035512015      Nattida    NaN\n",
       "15  16  6035512016     Nichakan    NaN\n",
       "16  17  6035512017      Pajaree    NaN\n",
       "17  18  6035512018      Panjira    NaN\n",
       "18  19  6135512002     Pattanun    NaN\n",
       "19  20  6035512019     Phimwadi    NaN\n",
       "20  21  6035512020    Phiraphon    NaN\n",
       "21  22  6135512005     Ruchikon    NaN\n",
       "22  23  6035512021        Santi    NaN\n",
       "23  24  6035512022    Santiphap    NaN\n",
       "24  25  6035512023    Sarawadee    NaN\n",
       "25  26  6035512024      Sarayut    NaN\n",
       "26  27  6035512025      Sorawit    NaN\n",
       "27  28  6135512028       Sufian    NaN\n",
       "28  29  6035512026   Sutthisarn    NaN\n",
       "29  30  6135512016       Tannut    NaN\n",
       "30  31  6035512027    Teeraphat    NaN\n",
       "31  32  6035512028     Teerayut    NaN\n",
       "32  33  6035512029    Thodsapon    NaN\n",
       "33  34  6035512030     Waraporn    NaN\n",
       "34  35  6135512053    Warinthon    NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d4d61b936b60b5bc6ff9fb0e62222b0cfefae76eccb24eb6ffe2e80675ee1b9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
